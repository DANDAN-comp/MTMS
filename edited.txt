
app.logger.setLevel(logging.DEBUG)

# Set up SQLite database URI
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///despatch_data.db'  # Database will be stored locally
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False  # Disable track modifications to avoid warning

client = MongoClient('mongodb://localhost:27017/')
db = client['yourDatabase']

# Initialize the SQLAlchemy extension
db = SQLAlchemy(app)
migrate = Migrate(app, db)

# Function to refresh data in the Excel file
def refresh_excel_data(file_stream):
    try:
        workbook = openpyxl.load_workbook(file_stream)
        # Refresh data in 'Stores DespatchNoteItems' sheet
        if 'Stores DespatchNoteItems' in workbook.sheetnames:
            sheet = workbook['Stores DespatchNoteItems']
            # Add your logic to refresh data here
            # Example: sheet['A1'] = 'Updated Value'

        # Refresh data in 'Structure Parts' sheet
        if 'Structure Parts' in workbook.sheetnames:
            sheet = workbook['Structure Parts']
            # Add your logic to refresh data here
            # Example: sheet['A1'] = 'Updated Value'

        # Save the workbook to a BytesIO stream
        updated_file_stream = BytesIO()
        workbook.save(updated_file_stream)
        updated_file_stream.seek(0)
        return updated_file_stream
    except Exception as e:
        print(f"Error refreshing Excel data: {e}")
        raise


# Main function to download, refresh, and upload the file
def process_file():
    try:
        # Download the file
        file_stream = get_sharepoint_file(file_url_despatch)

        # Refresh the data in the Excel file
        updated_file_stream = refresh_excel_data(file_stream)

        # Upload the updated file back to SharePoint
        upload_to_sharepoint(file_url_despatch, updated_file_stream)
    except Exception as e:
        print(f"Error in process_file: {e}")

# Function to load the data into a local SQLite database
def load_data_to_db():
    try:
        # Retrieve the file from SharePoint
        file_stream = get_sharepoint_file(file_url_despatch)

        # Read the Excel file into DataFrames
        despatch_columns = ['Sales.SalesOrderDetails.PartID', 'DespatchNote', 'SalesOrderNumber', 'LineNumber', 'DespatchQuantity', 'DespatchDate', 'Stores.DespatchNotes.CustomerID']
        despatch_df = pd.read_excel(file_stream, sheet_name="Stores DespatchNoteItems", usecols=despatch_columns, engine="openpyxl")

        parts_df = pd.read_excel(file_stream, sheet_name="Structure Parts", engine="openpyxl")

        # Convert 'PartID' to a dictionary for faster lookup
        parts_dict = parts_df.set_index('PartID')['PartNumber'].to_dict()

        # Map the Part Number
        despatch_df['Part Number'] = despatch_df['Sales.SalesOrderDetails.PartID'].map(parts_dict).fillna('N/A')

        # Handle default values for missing columns
        despatch_df['Customer Code'] = despatch_df.get('Customer Code', 'TOM')

        # Create an SQLite engine (or MySQL/PostgreSQL engine)
        engine = create_engine(db_url)

        # Store the data in the SQLite database
        despatch_df.to_sql('despatch_data', con=engine, if_exists='replace', index=False)
        print("Data loaded into the local database successfully!")

    except Exception as e:
        print(f"Error loading data to DB: {e}")

# Schedule the task to run every 5 minutes
def schedule_task():
    schedule.every(5).minutes.do(load_data_to_db)

    # Keep the scheduler running in a loop
    while True:
        schedule.run_pending()
        time.sleep(60)  # Wait 60 seconds before checking aga

# Define Flask route for testing
@app.route('/get_despatch_data', methods=['GET'])
def get_despatch_data():
    try:
        selected_date = request.args.get('date')

        # Query the data from the database
        engine = create_engine(db_url)
        query = "SELECT * FROM despatch_data"

        # Fetch data from DB
        despatch_df = pd.read_sql(query, con=engine)

        if selected_date:
            despatch_df['DespatchDate'] = pd.to_datetime(despatch_df['DespatchDate'])
            despatch_df = despatch_df[despatch_df['DespatchDate'].dt.strftime('%Y-%m-%d') == selected_date]

        # Convert the DataFrame to a dictionary and return as JSON
        data = despatch_df.to_dict(orient='records')
        return jsonify({'data': data})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/get_price_from_donite_sheet', methods=['POST'])
def get_price_from_donite_sheet_route():
    data = request.json
    part_no = data.get('partNo')
    qty_shipped = data.get('qtyShipped')
    regex_search = data.get('regex', False)
    price = get_price_from_donite_sheet(part_no, qty_shipped, regex_search)
    return jsonify({"price": price})

PPAR:
@app.route('/save_form', methods=['POST'])
def save_form():
    # Get all selected checkboxes for Mould and Jig sections
    mould_selected = []
    jig_selected = []
    check_wo =[]
    check_visual=[]
    final_checks=[]
    cutter_used=[]
    final_check=[]
    # Capture data for the Dimensional Grid
    dimensional_grid_refs = []
    dimensions = []
    tolerances = []
    actual_dimensions = []
    acceptables = []

    for i in range(10):  # Assuming 10 rows
        grid_ref = request.form.get(f'grid_ref_{i}')
        dimension = request.form.get(f'dimension_{i}')
        tolerance = request.form.get(f'tolerance_{i}')
        actual_dimension = request.form.get(f'actual_dimension_{i}')
        acceptable = request.form.get(f'acceptable_{i}')

        # Replace blank fields with "N/A"
        dimensional_grid_refs.append(grid_ref if grid_ref else "N/A")
        dimensions.append(dimension if dimension else "N/A")
        tolerances.append(tolerance if tolerance else "N/A")
        actual_dimensions.append(actual_dimension if actual_dimension else "N/A")
        acceptables.append(acceptable if acceptable else "N/A")

    # Add selected checkboxes for Mould
    if 'mould-base' in request.form:
        mould_selected.append("Base")
    if 'mould-vac-former' in request.form:
        mould_selected.append("Vac Former")
    if 'mould-vacuum-holes' in request.form:
        mould_selected.append("Vacuum Holes")
    if 'mould-clean' in request.form:
        mould_selected.append("Clean")
    if 'mould-sealed' in request.form:
        mould_selected.append("Sealed")
    if 'mould-temp-control' in request.form:
        mould_selected.append("Temp Control")

    # Add selected checkboxes for Jig
    if 'jig-vacuum' in request.form:
        jig_selected.append("Vacuum")
    if 'jig-plate-location' in request.form:
        jig_selected.append("Plate/Location")

    # Add selected checkboxes for check wo
    if 'check-wo-rev' in request.form:
        check_wo.append("Rev")
    if  'check-wo-material' in request.form:
        check_wo.append("Material")
    if  'check-wo-process' in request.form:
        check_wo.append("Process")

    # Add selected checkboxes for check wo
    if 'check-visual-imperfections' in request.form:
        check_visual.append("Tool free of Imperfections")
    if 'check-visual-Parttexture' in request.form:
        check_visual.append("Suitable Part Texture")

        # Add selected checkboxes for check wo
    if 'final-check-remov' in request.form:
        final_check.append("Remove Old Programs")
    if 'final-check-readi' in request.form:
        final_check.append("Trimming process ready for production")

        # Add selected checkboxes for check wo
    if 'cutter-used-⌀2' in request.form:
        cutter_used.append("⌀2")
    if 'cutter-used-⌀3' in request.form:
        cutter_used.append("⌀3")
    if 'cutter-used-⌀6' in request.form:
        cutter_used.append("⌀6")
    if 'cutter-used-Upcut' in request.form:
        cutter_used.append("Upcut")
    if 'cutter-used-Straight' in request.form:
        cutter_used.append("Straight")
    if 'cutter-used-Downcut' in request.form:
        cutter_used.append("Downcut")
    if 'cutter-used-⌀30' in request.form:
        cutter_used.append("⌀30")
    if 'cutter-used-⌀40' in request.form:
        cutter_used.append("⌀40")
    if 'cutter-used-⌀50' in request.form:
        cutter_used.append("⌀50")
    if 'cutter-used-Disk' in request.form:
        cutter_used.append("Disk")
    if 'cutter-used-Saw' in request.form:
        cutter_used.append("Saw")

      # Add selected checkboxes for check wo
    if 'final-check-remove' in request.form:
        final_checks.append("Remove Old Programs")
    if 'final-check-ready' in request.form:
        final_checks.append("Vacuum forming process ready for production")

    # Ensure the part number is provided
    part_number = request.form.get('part_number')
    if not part_number:
        return jsonify({"error": "part_number is required"}), 400

    # Get the other values from the form
    Customer_Name = request.form.get('customer_name')
    Inspected_by = request.form.get('inspected_by')
    Part_description = request.form.get('part_description')
    WO_Number = request.form.get('wo_number')
    Revision_Number = request.form.get('revision_number')
    Date = request.form.get('date')
    issues_and_suggested_solutions = request.form.get('issues_and_suggested_solutions')
    tooling_ready = request.form.get('tooling_ready')
    print("Tooling Ready Value Received:", tooling_ready)
    suggested_tool_temp= request.form.get('suggested_tool_temp')
    signed_off_by = request.form.get('signed_off_by')
    vacprogram_saved = request.form.get('vacprogram_saved')
    vac_program_name=request.form.get('vac-program-name')
    required_cycle_time=request.form.get('required_cycle_time')
    achieved_cycle_time=request.form.get('achieved_cycle_time')
    issues=request.form.get('issues')
    tool_temp=request.form.get('tool_temp')
    sign=request.form.get('sign')
    datee=request.form.get('datee')
    failure_attempt = request.form.get('failure-attempt')
    trim_pgm_saved=request.form.get('trim-pgm-saved')
    trim_pgm_name=request.form.get('trim-pgm-name')
    reqd_cycle_time=request.form.get('reqd-cycle-time')
    achevd_cycle_time=request.form.get('achevd-cycle-time')
    issue=request.form.get('issue')
    run_onn=request.form.get('run-on-ares')
    run_on = request.form.get('run-on-grimme')
    fail_attempt=request.form.get('failure-attempt')
    signature=request.form.get('signatur')
    Dte=request.form.get('Dte')
    descriptionn=request.form.get('descriptionn')
    fair_sign=request.form.get('fair_sign')
    dates=request.form.get('dates')
    name=request.form.get('signatureee')
    dat=request.form.get('dat')
    Tooling=request.form.get('tool')
    toolfail=request.form.get('failure-attemptt')
    tooldate=request.form.get('da')
    totalvac=request.form.get('Vac')
    totaltrim=request.form.get('trim')


    # Creating the data dictionary to be added to the Excel file
    data = {
        "CUSTOMER NAME": Customer_Name,
        "PART NUMBER": part_number,
        "INSPECTED BY": Inspected_by,
        "PART DESCRIPTION": Part_description,
        "WO NUMBER": WO_Number,
        "REVISION NUMBER": Revision_Number,
        "DATE": Date,
        "MOULD": ", ".join(mould_selected),  # Combine selected checkboxes into a string
        "JIG": ", ".join(jig_selected),  # Combine selected checkboxes into a string
        "ISSUES AND SUGGESTED SOLUTIONS": issues_and_suggested_solutions,
        "TOOLING READY?": tooling_ready,
        "SUGGESTED TOOL TEMP (°C)": suggested_tool_temp,
        "SIGNED OFF BY": signed_off_by,
        "CHECK WO": ", ".join(check_wo),
        "CHECK VISUAL": ", ".join(check_visual),
        "VAC PROGRAM SAVED": vacprogram_saved,
        "VAC PROGRAM NAME": vac_program_name,
        "REQUIRED CYCLE TIME/PART (MINS)":required_cycle_time,
        "CYCLE TIME ACHEIVED/PART (MINS)":achieved_cycle_time,
        "ISSUES":issues,
        "ACTUAL TOOL TEMP (°C)": tool_temp,
        "FINAL CHECKS": ", ".join(final_checks),
        "SIGNED  BY": sign,
        "DATE ": datee,
        "FAILURE ATTEMPT": failure_attempt,
        "TRIM PGM SAVED?":trim_pgm_saved,
        "TRIM PGM NAME":trim_pgm_name,
        "REQUIRED CYCLE TIME/PART(MIN)":reqd_cycle_time,
        "CYCLE TIME ACHEIVED/PART(MIN)": achevd_cycle_time,
        "ISSUE":issue,
        "RUN ON?":run_on or run_onn,
        "CUTTER USED":", ".join(cutter_used),
        "FINAL CHECK":", ".join(final_check),
        "TOTAL FAILURE ATTEMPT":fail_attempt,
        "SIGN BY":signature,
        "DATE COMPLETED": Dte,
        "DESCRIPTION":descriptionn,
        "FAIR COMPLETE":fair_sign,
        "COMPLETION DATE": dates,
        "PRODUCTION SIGN OFF":name,
        "DATE-":dat,
        "Dimensional Grid Ref": ",".join(dimensional_grid_refs),
        "Dimension (mm or Deg)": ",".join(dimensions),
        "Tolerance": ",".join(tolerances),
        "Actual Dimension (mm or Deg)": ",".join(actual_dimensions),
        "Acceptable (Y/N)": ",".join(acceptables),
        "TOTAL TOOLING": Tooling,
        "FAIL-SECTION 2": toolfail,
        "TOOLING DATE": tooldate,
        "TOTAL VAC COMPLETED": totalvac,
        "TOTAL TRIM COMPLETED": totaltrim,
    }
    print("Data to be written to Excel:", data)  # Debugging line

    try:
        # Assuming you have a function to get the file from SharePoint
        file_stream = get_sharepoint_file(file_url_section1)
        workbook = openpyxl.load_workbook(file_stream)
        sheet = workbook.active

        # Print the first few rows for debugging
        print("First 5 rows of the sheet:")
        for row in sheet.iter_rows(min_row=1, max_row=5, values_only=True):
            print(row)

        # Before writing, check the original content of the Excel file
        print("Before appending:")
        for row in sheet.iter_rows(values_only=True):
            print(row)

        # Check if the part number already exists in the sheet
        part_number_exists = False
        for row_idx, row in enumerate(sheet.iter_rows(min_row=2, values_only=True),
                                      start=2):  # Include row index for updating
            if str(row[1]) == str(part_number):  # Compare as strings to handle alphanumeric values
                part_number_exists = True
                print(f"Part number '{part_number}' found at row {row_idx}. Updating...")
                for col_num, value in enumerate(data.values(), start=1):
                    sheet.cell(row=row_idx, column=col_num, value=value)
                break

        if not part_number_exists:
            # Append the new data as a new row
            print(f"Part number '{part_number}' not found. Appending new row...")
            sheet.append(list(data.values()))

        # Debugging: Check if the data is added/updated in the sheet
        print("After modification:")
        for row in sheet.iter_rows(values_only=True):
            print(row)  # Print all rows to verify data

        # Save the modified workbook to a BytesIO object
        updated_file_stream = BytesIO()
        workbook.save(updated_file_stream)
        updated_file_stream.seek(0)

        # Upload the updated file back to SharePoint
        upload_to_sharepoint(file_url_section1, updated_file_stream)

        # Respond with a success message
        return jsonify({"message": "Data saved successfully"}), 200

    except Exception as e:
        # Log the error and return a failure message
        app.logger.error(f"Error while processing the form: {e}")
        return jsonify({"error": "Failed to save data to SharePoint"}), 500


@app.route('/search_part', methods=['GET'])
def search_part():
    part_number = request.args.get('part_number')
    ctx = ClientContext(site_url).with_credentials(UserCredential(username, password))

    # Create a file-like object to store the downloaded content
    file_object = io.BytesIO()
    response = ctx.web.get_file_by_server_relative_url(file_url_section1).download(file_object).execute_query()

    # Load the Excel file into a DataFrame
    file_object.seek(0)  # Reset the file pointer to the beginning
    df = pd.read_excel(file_object, sheet_name='Sheet1')  # Adjust sheet name as needed

    # Print column names for debugging
    print(df.columns)

    # Filter the DataFrame by part number
    try:
        filtered_df = df[df['PART NUMBER'] == part_number]
    except KeyError:
        return jsonify({"success": False, "message": "Column 'PART NUMBER' not found in the Excel file"}), 400

    if filtered_df.empty:
        return jsonify({"success": False, "message": "Part number not found"}), 404

    # Convert the filtered data to a list of dictionaries
    data = filtered_df.to_dict(orient='records')

    # Ensure all values are JSON serializable
    for record in data:
        for key, value in record.items():
            if isinstance(value, float) and pd.isna(value):
                record[key] = None  # Replace NaN with None
            elif isinstance(value, str):
                record[key] = value.replace('\u00b0', '°')  # Ensure special characters are properly encoded

    return jsonify({"success": True, "data": data})


MOULD TOOLS:

@app.route('/clear_db', methods=['POST'])
def clear_db():
    try:
        # Delete all records from the MouldTool table
        MouldTool.query.delete()
        db.session.commit()
        return jsonify({"message": "Database cleared successfully!"}), 200
    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@app.route("/import_csv", methods=["POST"])
def import_csv():
    file = request.files.get("file")  # Get the uploaded file from the form
    if not file:
        return jsonify({"status": "error", "message": "No file provided"}), 400

    if not file.filename.endswith(".csv"):
        return jsonify({"status": "error", "message": "File must be a CSV"}), 400

    try:
        stream = StringIO(file.stream.read().decode("utf-8"))
        csv_reader = csv.DictReader(stream)

        added_count = 0
        updated_count = 0

        for row in csv_reader:
            # Normalize headers to uppercase
            row = {key.strip().upper(): value.strip() for key, value in row.items()}

            # Identify if the row is from the new Excel format by checking for TOOL/JIG LOCATION and COMPANY NAME
            is_new_format = "TOOL/JIG LOCATION" in row and "COMPANY NAME" in row

            # Fill empty fields with "N/A" for the new format
            if is_new_format:
                row["TOOL/JIG LOCATION"] = row.get("TOOL/JIG LOCATION", "N/A")
                row["COMPANY NAME"] = row.get("COMPANY NAME", "N/A")
                row["TOOL NUMBER"] = row.get("TOOL NUMBER", "N/A")
                row["JIG NUMBER"] = row.get("JIG NUMBER", "N/A")
                row["TOOL LOCATION"] = row.get("TOOL LOCATION", "N/A")
                row["JIG LOCATION"] = row.get("JIG LOCATION", "N/A")

            # Get the value in the TOOL NUMBER column
            tool_jig_identifier = row.get("TOOL NUMBER", "").upper()
            location = row.get("TOOL/JIG LOCATION", "Unknown")
            company_name = row.get("COMPANY NAME", "Unknown")

            tool_number = None
            jig_number = None
            tool_location = None
            jig_location = None

            # Check if TOOL/JIG is in the TOOL NUMBER column
            if tool_jig_identifier:
                if "TOOL" in tool_jig_identifier:
                    tool_number = tool_jig_identifier
                    tool_location = location
                elif "JIG" in tool_jig_identifier:
                    jig_number = tool_jig_identifier
                    jig_location = location

            # If TOOL NUMBER is not in the new combined format, use the old format
            if not tool_number and not jig_number:
                tool_number = row.get("TOOL NUMBER", "")
                jig_number = row.get("JIG NUMBER", "")
                tool_location = row.get("TOOL LOCATION", "Unknown")
                jig_location = row.get("JIG LOCATION", "Unknown")

            # Ensure that only one of tool_number or jig_number is populated
            if not tool_number and not jig_number:
                continue  # Skip if both are empty

            # If jig_number is None, set it to a default value
            if jig_number is None:
                jig_number = ""  # or you can choose "Unknown" or other meaningful default

            # Fetch existing record if present
            existing_entry = None
            if tool_number:
                existing_entry = MouldTool.query.filter_by(tool_number=tool_number).first()
            elif jig_number:
                existing_entry = MouldTool.query.filter_by(jig_number=jig_number).first()

            # Update existing record or add new one
            if existing_entry:
                # Compare data to determine if an update is needed
                update_needed = False

                # Update tool location
                if tool_number and existing_entry.tool_location != tool_location:
                    existing_entry.tool_location = tool_location
                    update_needed = True

                # Update jig location
                if jig_number and existing_entry.jig_location != jig_location:
                    existing_entry.jig_location = jig_location
                    update_needed = True

                # Update company name
                if existing_entry.company_name_code != company_name:
                    existing_entry.company_name_code = company_name
                    update_needed = True

                if update_needed:
                    existing_entry.status = "Updated"
                    updated_count += 1
                    print(f"Updated entry: {tool_number or jig_number}")
            else:
                # Add a new record only if the required fields are populated
                new_entry = MouldTool(
                    tool_number=tool_number,
                    jig_number=jig_number,  # Ensure jig_number is never None
                    tool_location=tool_location if tool_number else None,
                    jig_location=jig_location if jig_number else None,
                    company_name_code=company_name,
                    status="Imported"
                )
                db.session.add(new_entry)
                added_count += 1
                print(f"Added new entry: {tool_number or jig_number}")

        # Commit all changes
        db.session.commit()

        return jsonify({
            "status": "success",
            "message": f"Data imported successfully. {added_count} entries added, {updated_count} entries updated."
        }), 200

    except Exception as e:
        db.session.rollback()
        return jsonify({"status": "error", "message": f"An error occurred: {str(e)}"}), 500



# Route to export data from the database to a CSV file
@app.route("/export_csv", methods=["GET"])
def export_csv():
    try:
        # Fetch all tools from the database
        tools = MouldTool.query.all()

        # Create a CSV in memory
        output = StringIO()
        writer = csv.writer(output)
        writer.writerow(["tool_number", "tool_location", "jig_location"])  # CSV headers

        for tool in tools:
            writer.writerow([tool.tool_number, tool.tool_location, tool.jig_location])

        output.seek(0)

        # Send the CSV file as a response
        return send_file(
            StringIO(output.getvalue()),
            mimetype="text/csv",
            as_attachment=True,
            download_name="tools_data.csv"
        )

    except Exception as e:
        return jsonify({"status": "error", "message": f"An error occurred: {str(e)}"}), 500






@app.route("/search_tools", methods=["POST"])
def search_tools():
    search_number = request.form.get('tool_number', '')
    search_location = request.form.get('tool_location', '')
    search_jig_number = request.form.get('jig_number', '')
    search_jig_location = request.form.get('jig_location', '')
    search_company = request.form.get('company_name_code', '')
    search_status = request.form.get('status', '')

    query = MouldTool.query

    # Apply filters based on form inputs, only if the input is not empty
    if search_number:
        query = query.filter(MouldTool.tool_number.like(f'%{search_number}%'))
    if search_location:
        query = query.filter(MouldTool.tool_location.like(f'%{search_location}%'))
    if search_jig_number:
        query = query.filter(MouldTool.jig_number.like(f'%{search_jig_number}%'))
    if search_jig_location:
        query = query.filter(MouldTool.jig_location.like(f'%{search_jig_location}%'))
    if search_company:
        query = query.filter(MouldTool.company_name_code.like(f'%{search_company}%'))
    if search_status and search_status != 'All':
        query = query.filter(MouldTool.status == search_status)

    tools = query.all()

    # Prepare the results to send back to the front end
    results = []
    for tool in tools:
        jig_number = tool.jig_number if tool.jig_number else "N/A"
        jig_location = tool.jig_location if tool.jig_location else "N/A"

        results.append({
            "tool_number": tool.tool_number,
            "tool_location": tool.tool_location,
            "status": tool.status,
            "jig_number": jig_number,
            "jig_location": jig_location,
            "company_name_code": tool.company_name_code,
            "id": tool.id
        })

    return jsonify({"tools": results})


@app.route("/get_tool/<int:tool_id>", methods=["GET"])
def get_tool(tool_id):
    tool = MouldTool.query.get_or_404(tool_id)
    return jsonify(tool.to_dict())


# Route to view all Mould Tool entries
@app.route("/view_tools")
def view_tools():
    tools = MouldTool.query.all()  # Get all the entries from the database
    return render_template("view_tools.html", tools=tools)
@app.route("/update_tool/<int:id>", methods=["POST"])
def update_tool(id):
    data = request.get_json()

    tool = MouldTool.query.get(id)
    if tool:
        tool.tool_number = data.get('tool_number')
        tool.tool_location = data.get('tool_location')
        tool.status = data.get('status')
        tool.jig_number = data.get('jig_number')
        tool.jig_location = data.get('jig_location')

        db.session.commit()
        return jsonify({"message": "Tool updated successfully!"}), 200
    else:
        return jsonify({"message": "Tool not found."}), 404

@app.route("/delete_tool/<int:id>", methods=["DELETE"])
def delete_tool(id):
    tool = MouldTool.query.get(id)
    if tool:
        db.session.delete(tool)
        db.session.commit()
        return jsonify({"message": "Tool deleted successfully!"}), 200
    else:
        return jsonify({"message": "Tool not found."}), 404


# Initialize the database (only run once to create the database file)
@app.before_request
def create_tables():
    db.create_all()

# Start the Flask app and the scheduled task in separate threads
if __name__ == '__main__':
    # Start the scheduler in a separate thread
    scheduler_thread = threading.Thread(target=schedule_task)
    scheduler_thread.daemon = True
    scheduler_thread.start()

    # Start the Flask app (this will run on the main thread)
    print("Starting Flask app...")
    app.run(debug=True, use_reloader=False)  # `use_reloa